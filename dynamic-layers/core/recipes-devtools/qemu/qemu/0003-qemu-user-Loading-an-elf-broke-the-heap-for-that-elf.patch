From f2f7efd55a2f2c533855949e18b849fb0bb7c826 Mon Sep 17 00:00:00 2001
From: Heinz Wrobel <Heinz.Wrobel@nxp.com>
Date: Tue, 5 Feb 2019 07:13:43 +0100
Subject: [PATCH 3/3] qemu-user: Loading an elf broke the heap for that elf

This is a key fix to enable running more complex guest applications.
The original method of using target_mmap just allocated to any address.
This allocated stack and interpreter data just beyond the loaded image.
As a result there was not brk() space left and the guest heap handling
failed. The ugly part about this is that, depending on the guest, this
could lead to all sorts of very weird effects, not obviously related
to memory management at all.
The fix is to ensure that there is plenty of space after the loaded
relocatable image and to move stack and interpreter loads to the end
of the memory map. This way, the image, the target_mmap space, and
stack+interpreter are well separated and heap extension via brk()
works again for the guest.

Signed-off-by: Heinz Wrobel <Heinz.Wrobel@nxp.com>
---
 linux-user/elfload.c | 55 ++++++++++++++++++++++++++++++++++++++++++++++++----
 1 file changed, 51 insertions(+), 4 deletions(-)

diff --git a/linux-user/elfload.c b/linux-user/elfload.c
index 09849f7..af07da4 100644
--- a/linux-user/elfload.c
+++ b/linux-user/elfload.c
@@ -1543,6 +1543,26 @@ static abi_ulong copy_elf_strings(int argc, char **argv, char *scratch,
     return p;
 }
 
+static abi_long elf_target_mmap(struct image_info *info,
+                                abi_ulong len, int prot, int flags)
+{
+    abi_long addr;
+
+    /* We don't want to allocate to just any address even for
+     * relocatable code because it might break the order of
+     * code/data/heap/free/mmap/other stuff and break heap extension.
+     * So we are a bit create and allocate sequentially from start_mmap
+     * when loading the original elf image.
+     */
+    addr = target_mmap(info->start_mmap, len, prot, flags, -1, 0);
+    if (addr == info->start_mmap) {
+        len = ROUND_UP(len, MAX(qemu_host_page_size, TARGET_PAGE_SIZE));
+        info->start_mmap += len;
+    }
+
+    return addr;
+}
+
 /* Older linux kernels provide up to MAX_ARG_PAGES (default: 32) of
  * argument/environment space. Newer kernels (>2.6.33) allow more,
  * dependent on stack size, but guarantee at least 32 pages for
@@ -1564,7 +1584,20 @@ static abi_ulong setup_arg_pages(struct linux_binprm *bprm,
         guard = qemu_real_host_page_size;
     }
 
-    error = target_mmap(0, size + guard, PROT_READ | PROT_WRITE,
+    /* We cannot just allocate to any address because we might
+     * allocate right after the brk of the just loaded image.
+     * This then breaks heap allocation because there is no heap
+     * of any reasonable size then. So as a consequence, the loaded
+     * application will fail. So we need to figure out how to
+     * allocate the stack to the end of the memory map. But what is
+     * that?! Hmm. Well, we can try a magic hack that gives us plenty
+     * of heap hopefully by allocating in a space that should be
+     * available and not conflicting with the brk of the loaded image.
+     * The hack is to allocate to the address known to be already
+     * allocated. Then target_mmap and the kernel allocates to the end.
+     */
+    error = target_mmap((abi_ulong)ELF_START_MMAP, size + guard,
+                        PROT_READ | PROT_WRITE,
                         MAP_PRIVATE | MAP_ANONYMOUS, -1, 0);
     if (error == -1) {
         perror("mmap stack");
@@ -2014,6 +2047,8 @@ static void load_elf_image(const char *image_name, int image_fd,
     int i, retval;
     const char *errmsg;
 
+    qemu_log_mask(CPU_LOG_PAGE, "loading elf image '%s'\n", image_name);
+
     /* First of all, some simple consistency checks */
     errmsg = "Invalid ELF image for this architecture";
     if (!elf_check_ident(ehdr)) {
@@ -2069,9 +2104,8 @@ static void load_elf_image(const char *image_name, int image_fd,
            image is pre-linked, LOADDR will be non-zero.  Since we do
            not supply MAP_FIXED here we'll use that address if and
            only if it remains available.  */
-        load_addr = target_mmap(loaddr, hiaddr - loaddr, PROT_NONE,
-                                MAP_PRIVATE | MAP_ANON | MAP_NORESERVE,
-                                -1, 0);
+        load_addr = elf_target_mmap(info, hiaddr - loaddr, PROT_NONE,
+                                MAP_PRIVATE | MAP_ANON | MAP_NORESERVE);
         if (load_addr == -1) {
             goto exit_perror;
         }
@@ -2451,6 +2485,19 @@ int load_elf_binary(struct linux_binprm *bprm, struct image_info *info)
     }
 
     if (elf_interpreter) {
+        /* This is a bit of an ugly trick. We again want to avoid
+         * allocating right after the brk of the initial image to
+         * keep heap management alive. So we define the same start
+         * address as the initial image. This means that going through
+         * the kernel mmap mechanism in the end we will get a result
+         * at the end of the memory map which is well out of the way
+         * and doesn't cause conflicts with either heap or the normal
+         * target_mmap allocation addresses. This is a bit empirical
+         * though in real life. I am not sure if you can depend on the
+         * kernel to allocate top down if you force a conflict.
+         */
+        interp_info.start_mmap = (abi_ulong)ELF_START_MMAP;
+
         load_elf_interp(elf_interpreter, &interp_info, bprm->buf);
 
         /* If the program interpreter is one of these two, then assume
-- 
1.8.3.1

